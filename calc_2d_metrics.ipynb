{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import imageio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte, io\n",
    "import cv2\n",
    "import glob\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "# pytorch ops\n",
    "from pytorch3d.ops import knn_gather, knn_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sampling_metrics_2d(pred_points, gt_points, thresholds, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute metrics that are based on sampling points from 2D image:\n",
    "    - L2 Chamfer distance\n",
    "    - Precision at various thresholds\n",
    "    - Recall at various thresholds\n",
    "    - F1 score at various thresholds\n",
    "    Inputs:\n",
    "        - pred_points: Tensor of shape (N, S, 3) giving coordinates of sampled points\n",
    "          for each predicted mesh\n",
    "        - gt_points: Tensor of shape (N, S, 3) giving coordinates of sampled points\n",
    "          for each ground-truth mesh\n",
    "        - thresholds: Distance thresholds to use for precision / recall / F1\n",
    "        - eps: epsilon value to handle numerically unstable F1 computation\n",
    "    Returns:\n",
    "        - metrics: A dictionary where keys are metric names and values are Tensors of\n",
    "          shape (N,) giving the value of the metric for the batch\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    lengths_pred = torch.full(\n",
    "        (pred_points.shape[0],), pred_points.shape[1], dtype=torch.int64, device=pred_points.device\n",
    "    )\n",
    "    lengths_gt = torch.full(\n",
    "        (gt_points.shape[0],), gt_points.shape[1], dtype=torch.int64, device=gt_points.device\n",
    "    )\n",
    "\n",
    "    # For each predicted point, find its neareast-neighbor GT point\n",
    "    knn_pred = knn_points(pred_points, gt_points, lengths1=lengths_pred, lengths2=lengths_gt, K=1)\n",
    "    # Compute L1 and L2 distances between each pred point and its nearest GT\n",
    "    pred_to_gt_dists2 = knn_pred.dists[..., 0]  # (N, S)\n",
    "    pred_to_gt_dists = pred_to_gt_dists2.sqrt()  # (N, S)\n",
    "\n",
    "    # For each GT point, find its nearest-neighbor predicted point\n",
    "    knn_gt = knn_points(gt_points, pred_points, lengths1=lengths_gt, lengths2=lengths_pred, K=1)\n",
    "    # Compute L1 and L2 dists between each GT point and its nearest pred point\n",
    "    gt_to_pred_dists2 = knn_gt.dists[..., 0]  # (N, S)\n",
    "    gt_to_pred_dists = gt_to_pred_dists2.sqrt()  # (N, S)\n",
    "\n",
    "\n",
    "    # Compute L2 chamfer distances\n",
    "    chamfer_l2 = pred_to_gt_dists2.mean(dim=1) + gt_to_pred_dists2.mean(dim=1)\n",
    "    metrics[\"Chamfer-L2\"] = chamfer_l2\n",
    "\n",
    "    # Compute precision, recall, and F1 based on L2 distances\n",
    "    for t in thresholds:\n",
    "        precision = 100.0 * (pred_to_gt_dists < t).float().mean(dim=1)\n",
    "        recall = 100.0 * (gt_to_pred_dists < t).float().mean(dim=1)\n",
    "        f1 = (2.0 * precision * recall) / (precision + recall + eps)\n",
    "        metrics[\"Precision@%f\" % t] = precision\n",
    "        metrics[\"Recall@%f\" % t] = recall\n",
    "        metrics[\"F1@%f\" % t] = f1\n",
    "\n",
    "    # Move all metrics to CPU\n",
    "    metrics = {k: v.cpu() for k, v in metrics.items()}\n",
    "    return metrics\n",
    "\n",
    "def plt_imshow(title, image):\n",
    "    # convert the image frame BGR to RGB color space and display it\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "def get_grayscale_img(img_path):\n",
    "    ''' Get image and convert to grayscale. Also convert black background to white if detected '''\n",
    "    image = io.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if gray[0][0] != 255:\n",
    "        gray = 255 - gray\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    return gray\n",
    "\n",
    "def binarize_img(gray_img, threshold):\n",
    "    _, thresh = cv2.threshold(gray_img, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    return thresh\n",
    "\n",
    "def get_contour(img):\n",
    "    # want CHAIN_APPROX_NONE because it returns a more full list of points\n",
    "    contours, hierarchy  = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    # grab largest contour (idx 0 i think)\n",
    "    cnt_idx = 0\n",
    "    contour = np.squeeze(contours[cnt_idx]) # size: [N x 2]\n",
    "    return contour\n",
    "\n",
    "def draw_sampled_points(gray, points):\n",
    "    radius = 1\n",
    "    thickness = 1\n",
    "    contour_img = gray.copy()\n",
    "    for i in range(points.shape[0]):\n",
    "        image = cv2.circle(contour_img, tuple(points[i]), radius, [0, 255, 0], thickness)\n",
    "    return image\n",
    "\n",
    "def get_bbox(mask): # 'mask' should be the binary image where 0 is background and 1 is foreground. if this is switched on your binary image then instead pass (1 - mask)\n",
    "    sum_x = np.sum(mask,axis=0)\n",
    "    sum_y = np.sum(mask,axis=1)\n",
    "\n",
    "    x_min = np.nonzero(sum_y)[0][0] \n",
    "    x_max = np.nonzero(sum_y)[0][-1]\n",
    "\n",
    "    y_min = np.nonzero(sum_x)[0][0]\n",
    "    y_max = np.nonzero(sum_x)[0][-1]\n",
    "    return [x_min,x_max,y_min,y_max]\n",
    "\n",
    "def bbox_crop_img(img,bbox):\n",
    "    return img[bbox[0]:bbox[1],bbox[2]:bbox[3]]\n",
    "\n",
    "\n",
    "def make_square_2d(img,pad_val=0):\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    if h == w:\n",
    "        return img\n",
    "    elif w < h:\n",
    "        padamt = h - w\n",
    "        if padamt % 2 == 0:\n",
    "            padim = np.pad(img, ((0,0), (padamt//2, padamt//2)), mode='constant', constant_values=pad_val)\n",
    "        else:\n",
    "            padim = np.pad(img, ((0,0), (padamt//2, padamt//2+1)), mode='constant', constant_values=pad_val)\n",
    "    else:\n",
    "        padamt = w - h\n",
    "        if padamt % 2 == 0:\n",
    "            padim = np.pad(img, ((padamt//2, padamt//2), (0,0)), mode='constant', constant_values=pad_val)\n",
    "        else:\n",
    "            padim = np.pad(img, ((padamt//2, padamt//2+1), (0,0)), mode='constant', constant_values=pad_val)\n",
    "    if padim.shape[0] != padim.shape[1]:\n",
    "        assert False, 'failure in make_square'\n",
    "    return padim\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set relevant parameters (replace with path to your files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "f = open('results.csv', 'w')\n",
    "# write csv header\n",
    "f.write('object1,object2,CD,F@0.1,F@0.2,F@0.5\\n')\n",
    "\n",
    "lim_img=glob.glob(\"*_lim.png\")\n",
    "for img_path1 in lim_img:\n",
    "    prefix=img_path1.split(\"_\")[0]\n",
    "    other_imgs = glob.glob(prefix + \"*\")\n",
    "    other_imgs = [imgpath for imgpath in other_imgs if 'lim' not in imgpath]\n",
    "    for img_path2 in other_imgs:\n",
    "        obj1 = img_path1.split('/')[-1][:-4]\n",
    "        obj2 = img_path2.split('/')[-1][:-4]\n",
    "        print(obj1,obj2)\n",
    "        # how many points to sample (if this is great than number of points in im1 or im2's contour it will\n",
    "        # get overrided with the # points of the smaller contour)\n",
    "        n_points_to_sample = 100\n",
    "        gray1 = get_grayscale_img(img_path1)\n",
    "        gray2 = get_grayscale_img(img_path2)\n",
    "        img_dim = gray1.shape[0] # used later to normalize sampled points, assumes square images\n",
    "\n",
    "        plt.imshow(gray1, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(\"grayscale image 1\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(gray2, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(\"grayscale image 2\")\n",
    "        plt.show()\n",
    "        thresh_val = 250\n",
    "        img = gray1\n",
    "        mask1 = binarize_img(gray1, thresh_val) # your binary/threshold image (should be dimensions WxH)\n",
    "        bbox = get_bbox(mask1)\n",
    "        mask1 = make_square_2d(bbox_crop_img(mask1,bbox), 0)\n",
    "        gray1 = make_square_2d(bbox_crop_img(gray1,bbox), 255)\n",
    "\n",
    "        img = gray2\n",
    "        mask2 = binarize_img(gray2, thresh_val) # your binary/threshold image (should be dimensions WxH)\n",
    "        bbox = get_bbox(mask2)\n",
    "        mask2 = make_square_2d(bbox_crop_img(mask2,bbox), 0)\n",
    "        gray2 = make_square_2d(bbox_crop_img(gray2,bbox), 255)\n",
    "\n",
    "        mask1=cv2.resize(mask1, (100,100)) \n",
    "        mask2=cv2.resize(mask2, (100,100))\n",
    "        \n",
    "        gray1=cv2.resize(gray1, (100,100)) \n",
    "        gray2=cv2.resize(gray2, (100,100))\n",
    "\n",
    "        plt.imshow(gray1, cmap='gray')\n",
    "        plt.title(\"grayscale image 1\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(gray2, cmap='gray')\n",
    "        plt.title(\"grayscale image 2\")\n",
    "        plt.show()\n",
    "\n",
    "        # show extra details\n",
    "        print(np.unique(gray1))\n",
    "        print(bbox)\n",
    "        plt.imshow(mask1)\n",
    "        plt.show()\n",
    "        plt.imshow(mask2)\n",
    "        plt.show()\n",
    "\n",
    "        assert mask1.shape == mask2.shape, 'IMAGES MUST BE SAME DIMESIONS'\n",
    "        assert mask1.shape[0] == mask1.shape[1], 'IMAGES MUST BE SQUARE'\n",
    "\n",
    "        contour1 = get_contour(mask1)\n",
    "        contour2 = get_contour(mask2)\n",
    "\n",
    "        n_points1 = contour1.shape[0]\n",
    "        n_points2 = contour2.shape[0]\n",
    "        print('found contour on img 1 with', n_points1, 'points')\n",
    "        print('found contour on img 2 with', n_points2, 'points')\n",
    "        print('sampling', n_points_to_sample, 'of them')\n",
    "        if n_points_to_sample > min(n_points1,n_points2):\n",
    "            print('not enough points to sample! overriding n_points_to_sample..')\n",
    "            n_points_to_sample = min(n_points1,n_points2)\n",
    "            print('sampling', n_points_to_sample, 'now')\n",
    "\n",
    "        sampled_idxes = np.random.choice(np.arange(n_points1), n_points_to_sample, replace=False)\n",
    "        sampled_points1 = contour1[sampled_idxes] # size: [n_points_to_sample x 2]\n",
    "        sampled_idxes = np.random.choice(np.arange(n_points2), n_points_to_sample, replace=False)\n",
    "        sampled_points2 = contour2[sampled_idxes] # size: [n_points_to_sample x 2]\n",
    "\n",
    "        vis_points1 = draw_sampled_points(gray1, sampled_points1)\n",
    "        vis_points2 = draw_sampled_points(gray2, sampled_points2)\n",
    "\n",
    "        plt.imshow(vis_points1, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title('sampled points 1')\n",
    "        plt.show()\n",
    "        plt.imshow(vis_points2, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title('sampled points 2')\n",
    "        plt.show()\n",
    "\n",
    "        thresholds = [0.1, 0.2, 0.5]\n",
    "        pts1 = torch.tensor(sampled_points1).unsqueeze(0) / img_dim # normalize pts to 0-1 range\n",
    "        pts2 = torch.tensor(sampled_points2).unsqueeze(0) / img_dim # normalize pts to 0-1 range\n",
    "        # scale by 10 to be more comparable with meshes (i think?)\n",
    "        pts1 = pts1 * 10.0\n",
    "        pts2 = pts2 * 10.0\n",
    "\n",
    "        result = compute_sampling_metrics_2d(pts1, pts2, thresholds)\n",
    "        print('Chamfer distance:', result['Chamfer-L2'].item()) # lower is better\n",
    "        print('F-score @ 0.1:', result['F1@0.100000'].item()) # higher is better\n",
    "        print('F-score @ 0.2:', result['F1@0.200000'].item()) # higher is better\n",
    "        print('F-score @ 0.5:', result['F1@0.500000'].item()) # higher is better\n",
    "        \n",
    "        # write to file\n",
    "        f.write('%s,%s,%f,%f,%f,%f\\n'%(obj1,obj2,result['Chamfer-L2'].item(), result['F1@0.100000'].item(), result['F1@0.200000'].item(), result['F1@0.500000'].item()))\n",
    "        \n",
    "# close file writer\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path=\"#3Superellipse_Dsh.png\"\n",
    "img=io.imread(img_path)\n",
    "print(img.shape)\n",
    "print(np.unique(img[:,:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image (must be square and same size for the rest to make sense!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binarize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find contour points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
